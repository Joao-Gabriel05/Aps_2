{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "df = pd.read_csv('dados/teste.csv')\n",
    "metade = len(df)/2\n",
    "df_teste = df[:20]\n",
    "df_treino = df[int(metade):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limpa_texto(df):\n",
    "    pontuacao = [',', '.', ';', ':', '!', '?', '-', '(', ')', '[', ']', '{', '}', '\"', '/', '\\\\', '|', '_', '+', '=', '*', '&', '@', '#', '$', '%', '^', '<','>','`','~']\n",
    "    lista = []\n",
    "    for palavras in df:\n",
    "        lista.append(palavras)\n",
    "    string = ' '.join(lista)\n",
    "    if '<br /><br />' in string:\n",
    "        string = string.replace('<br /><br />', ' ')\n",
    "    for pontos in pontuacao:\n",
    "        if pontos in string:\n",
    "            string = string.replace(f'{pontos}','')\n",
    "    lista = re.split(r'\\s+|\\W+', string.lower())\n",
    "    lista = [palavra for palavra in lista if palavra]\n",
    "    return lista\n",
    "\n",
    "def limpa_texto_review(df):\n",
    "    pontuacao = [',', '.', ';', ':', '!', '?', '-', '(', ')', '[', ']', '{', '}', '\"', '/', '\\\\', '|', '_', '+', '=', '*', '&', '@', '#', '$', '%', '^', '<','>','`','~']\n",
    "    lista = df.split(' ') \n",
    "    string = ' '.join(lista)\n",
    "    if '<br /><br />' in string:\n",
    "        string = string.replace('<br /><br />', ' ')\n",
    "    for pontos in pontuacao:\n",
    "        if pontos in string:\n",
    "            string = string.replace(f'{pontos}','')\n",
    "    lista = re.split(r'\\s+|\\W+', string.lower())\n",
    "    lista = [palavra for palavra in lista if palavra]\n",
    "    return lista\n",
    "\n",
    "lista_total = limpa_texto(df_teste['review'])\n",
    "\n",
    "filtro_positivo = df_teste['sentiment'] == 'positive'\n",
    "df_positivo = df_teste[filtro_positivo]\n",
    "lista_positivo = limpa_texto(df_positivo['review'])\n",
    "\n",
    "filtro_negativo = df_teste['sentiment'] == 'negative'\n",
    "df_negativo = df_teste[filtro_negativo]\n",
    "lista_negativo = limpa_texto(df_negativo['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_contagem_total = {}\n",
    "for i in range(len(df_teste)):\n",
    "    lista_arrumada = limpa_texto_review(df_teste.iloc[i]['review'])\n",
    "    lista_arrumada_unique = list(set(lista_arrumada))\n",
    "\n",
    "    for palavras in lista_arrumada_unique:    \n",
    "        if palavras not in dic_contagem_total:\n",
    "            dic_contagem_total[palavras] = 1\n",
    "        else:\n",
    "            dic_contagem_total[palavras] += 1\n",
    "\n",
    "dic_probabilidades_total = {}\n",
    "for palavras, contagem in dic_contagem_total.items():\n",
    "    dic_probabilidades_total[palavras] = contagem/len(df_teste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "dic_contagem_positivo = {}\n",
    "for i in range(len(df_positivo)):\n",
    "    lista_arrumada = limpa_texto_review(df_positivo.iloc[i]['review'])\n",
    "    lista_arrumada_unique = list(set(lista_arrumada))\n",
    "\n",
    "    for palavras in lista_arrumada_unique:    \n",
    "        if palavras not in dic_contagem_positivo:\n",
    "            dic_contagem_positivo[palavras] = 1\n",
    "        else:\n",
    "            dic_contagem_positivo[palavras] += 1\n",
    "\n",
    "dic_probabilidades_positivo = {}\n",
    "for palavras, contagem in dic_contagem_positivo.items():\n",
    "    dic_probabilidades_positivo[palavras] = contagem/len(df_positivo)\n",
    "\n",
    "dic_probabilidades_barrada_positivo = {}\n",
    "for palavra, probabilidade in dic_probabilidades_positivo.items():\n",
    "    dic_probabilidades_barrada_positivo[palavra] = 1-probabilidade\n",
    "\n",
    "for palavras in lista_negativo:\n",
    "    if palavras not in dic_probabilidades_barrada_positivo:\n",
    "        dic_probabilidades_barrada_positivo[palavras] = 1\n",
    "print(dic_probabilidades_positivo['one'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'some': 0.4, 'ok': 0.1, 'its': 0.4, 'the': 1.0, 'i': 1.0, 'thriller': 0.1, 'this': 1.0, 'watchable': 0.1, 'well': 0.1, 'real': 0.3, 'zombie': 0.1, 'or': 0.7, 'life': 0.2, 'parents': 0.1, 'boy': 0.1, 'slower': 0.1, 'first': 0.5, 'as': 0.6, 'divorcing': 0.1, 'just': 0.7, '3': 0.1, 'kill': 0.1, 'dialogs': 0.1, 'time': 0.3, 'them': 0.5, 'ruins': 0.1, 'with': 0.6, 'ignore': 0.1, 'decides': 0.1, 'instead': 0.2, 'shots': 0.1, 'totally': 0.1, 're': 0.1, 'when': 0.4, 'is': 0.8, 'then': 0.3, 'you': 0.4, 'little': 0.1, 'than': 0.3, 'of': 1.0, 'and': 1.0, 'meaningless': 0.1, 'have': 0.6, 'watched': 0.1, 'see': 0.4, 'family': 0.1, 'decide': 0.2, 'we': 0.3, 'make': 0.2, 'playing': 0.2, 'which': 0.1, 'jake': 0.1, 'if': 0.6, 'to': 1.0, 'drama': 0.1, 'spots': 0.1, 'soap': 0.1, 'arguing': 0.1, 's': 0.7, 'out': 0.4, 'all': 0.4, 'are': 0.5, 'fighting': 0.2, 'basically': 0.1, 'must': 0.3, 'in': 1.0, '10': 0.2, 'boogeyman': 0.1, 'where': 0.3, 'closet': 0.1, 'there': 0.6, 'film': 0.7, 'suddenly': 0.1, 'thinks': 0.1, 'going': 0.3, 'his': 0.3, 'movie': 0.6, 'become': 0.1, 'expected': 0.1, 'rambo': 0.1, 'similar': 0.3, 'a': 1.0, 'opera': 0.1, 'descent': 0.1, 'like': 0.4, 'for': 0.8, 'years': 0.1, 'hacks': 0.1, 'idea': 0.1, 'huge': 0.1, '70': 0.1, 'brilliant': 0.2, 'stars': 0.1, 'guesthosts': 0.1, 'can': 0.1, 'bad': 0.4, 'handselected': 0.1, 't': 0.6, 'replace': 0.1, 'off': 0.3, 'aired': 0.1, 'brilliance': 0.1, 'was': 0.8, 'really': 0.2, 'writing': 0.1, 'so': 0.6, 'entertaining': 0.1, '2': 0.1, 'find': 0.3, 'performances': 0.1, 'same': 0.2, 'chose': 0.1, 'show': 0.1, 'fallen': 0.1, 'it': 0.9, 'cast': 0.2, 'respect': 0.1, 'has': 0.1, 'success': 0.1, 'funny': 0.2, 'were': 0.4, 'on': 0.5, 'mediocrity': 0.1, '1990': 0.1, 'dropped': 0.1, 'truly': 0.2, 'felt': 0.1, 'mildly': 0.1, 'followed': 0.1, 'now': 0.2, 'not': 0.6, 'innovative': 0.1, 'by': 0.6, 'how': 0.2, 'probably': 0.1, 'recognize': 0.1, 'fit': 0.1, 'further': 0.1, '7': 0.1, 'awful': 0.4, 'wouldn': 0.1, 'fresh': 0.1, 'give': 0.2, 'an': 0.5, 'respite': 0.1, 'be': 0.6, 'almost': 0.2, 'decline': 0.1, 'band': 0.1, 'made': 0.4, 'painfully': 0.1, 'complete': 0.1, 'far': 0.4, 'today': 0.1, 'anymore': 0.2, 'believe': 0.1, 'but': 0.8, 'still': 0.2, 'original': 0.1, 'disgraceful': 0.1, 'continued': 0.1, 'one': 0.6, 'creator': 0.1, 'air': 0.2, 'amazing': 0.1, 'waste': 0.2, 'such': 0.2, 'after': 0.2, 'things': 0.2, 'also': 0.1, '8': 0.1, 'hard': 0.2, 'that': 0.8, 'comments': 0.1, 'every': 0.1, 'worst': 0.1, 'editing': 0.1, 'best': 0.1, 'obsessives': 0.1, 'way': 0.1, 'rarely': 0.1, '950': 0.1, 'keitel': 0.1, 'acting': 0.2, 'effort': 0.1, 'been': 0.3, 'from': 0.6, 'watching': 0.1, 'forward': 0.1, 'making': 0.3, 'while': 0.1, 'less': 0.1, 'extreme': 0.1, 'song': 0.1, 'prevents': 0.1, 'harvey': 0.1, 'four': 0.1, 've': 0.3, 'here': 0.2, 'seen': 0.2, 'looks': 0.1, 'no': 0.6, '1score': 0.1, 'only': 0.3, 'pacing': 0.1, 'seems': 0.1, 'about': 0.3, 'end': 0.4, 'least': 0.3, 'tune': 0.1, 'times': 0.1, 'happy': 0.2, 'positive': 0.1, 'he': 0.2, 'played': 0.3, 'at': 0.5, 'me': 0.3, 'bit': 0.1, 'country': 0.1, 'soundtrack': 0.1, 'nasty': 0.1, 'credits': 0.1, 'looking': 0.1, 'films': 0.4, 'storyline': 0.2, 'encouraged': 0.1, 'giving': 0.1, 'mistake': 0.1, 'performance': 0.1, 'cheap': 0.1, 'boring': 0.1, 'lame': 0.1, 'thing': 0.1, 'those': 0.2, 'everything': 0.2, 'imagine': 0.1, 'appeal': 0.1, 'alien': 0.1, 'interesting': 0.1, 'try': 0.1, 'jokes': 0.1, 'another': 0.2, 'low': 0.1, 'progressed': 0.1, 'punchlines': 0.1, 'very': 0.2, 'who': 0.3, 'problem': 0.1, 'thats': 0.2, 'actual': 0.1, 'never': 0.2, 'didn': 0.2, 'rather': 0.1, 'currently': 0.1, 'budget': 0.1, 'stoner': 0.1, 'itself': 0.2, 'partaking': 0.1, 'oddness': 0.1, 'something': 0.3, 'brother': 0.1, 'interest': 0.1, 'humour': 0.1, 'eventually': 0.1, 'lost': 0.2, 'based': 0.1, 'phil': 0.1, 'characters': 0.2, 'pretty': 0.3, 'would': 0.3, 'planet': 0.1, 'around': 0.1, 'odd': 0.1, 'quirky': 0.1, 'better': 0.2, 'since': 0.1, 'bird': 0.1, 'usually': 0.1, 'care': 0.1, 'romantic': 0.1, 'later': 0.1, 'might': 0.1, 'notice': 0.1, 'loved': 0.1, 'these': 0.2, 'story': 0.3, 'kid': 0.1, 'took': 0.1, '12': 0.1, 'professor': 0.1, 'bumped': 0.1, 'saturday': 0.1, 'plots': 0.1, 'janet': 0.1, 'eating': 0.2, 'scene': 0.3, 'young': 0.1, 'much': 0.2, 'scariest': 0.1, 'humor': 0.1, 'sat': 0.1, 'tired': 0.1, 'psycho': 0.1, 'came': 0.1, 'angle': 0.1, 'type': 0.1, 'year': 0.1, 'unintentional': 0.1, 'resolution': 0.1, 'movies': 0.2, 'helplessly': 0.1, 'leigh': 0.1, 'horror': 0.1, 'predictable': 0.1, 'daughter': 0.1, 'recall': 0.1, 'possible': 0.1, 'parachutes': 0.1, 'point': 0.1, 'love': 0.1, 'star': 0.2, 'hero': 0.1, 'rules': 0.1, 'b': 0.1, 'cheesy': 0.1, 'afternoons': 0.1, 'early': 0.1, 'woman': 0.1, 'screenwriters': 0.1, 'saw': 0.2, 'died': 0.1, 'monster': 0.2, 'included': 0.1, 'men': 0.1, 'beautiful': 0.1, 'up': 0.2, 'big': 0.3, 'scary': 0.1, 'old': 0.2, 'right': 0.2, 'formula': 0.1, 'dangling': 0.1, 'wellworn': 0.1, 'reminds': 0.1, 'however': 0.1, 'maybe': 0.1, 'stay': 0.1, 'research': 0.1, 'rights': 0.1, 'many': 0.1, 'minutes': 0.1, 'apparently': 0.1, 'imply': 0.1, 'finsished': 0.1, 'infiltrating': 0.1, 'go': 0.1, 'biz': 0.1, 'screen': 0.1, 'im': 0.1, 'scenes': 0.3, 'enjoyed': 0.1, 'use': 0.1, 'whole': 0.2, 'dr': 0.1, 'carver': 0.1, 'mehehe': 0.1, 'perspective': 0.1, 'rich': 0.1, 'called': 0.1, 'til': 0.1, 'good': 0.3, 'selfs': 0.1, 'even': 0.1, 'true': 0.2, 'will': 0.3, 'fan': 0.1, 'spoiler': 0.1, 'more': 0.3, 'enters': 0.1, 'gone': 0.1, 'island': 0.1, 'three': 0.1, 'feeling': 0.1, 'scientist': 0.1, 'they': 0.3, 'delivers': 0.1, 'located': 0.1, 'ahead': 0.1, 'loneley': 0.1, 'topsecret': 0.1, 'btw': 0.1, 'haven': 0.1, 'beyond': 0.2, 'evil': 0.1, 'started': 0.1, 'any': 0.2, 'sidekick': 0.1, 'labs': 0.1, 'mentioning': 0.1, 'again': 0.1, 'squad': 0.1, 'invites': 0.1, 'tropical': 0.1, 'set': 0.1, 'ralf': 0.1, 'people': 0.2, 'agenda': 0.1, 'laugh': 0.1, 'lumberjackwoods': 0.1, 'did': 0.2, 'secret': 0.1, 'reeks': 0.1, 'kicking': 0.1, 'staying': 0.1, 'gms': 0.1, 'badass': 0.1, 'tale': 0.1, 'bratwurst': 0.1, 'don': 0.1, 'simpletons': 0.1, 'goes': 0.2, 'palm': 0.1, 'suck': 0.1, 'together': 0.1, 'should': 0.1, 'jack': 0.1, 'performing': 0.1, 'boat': 0.1, 'got': 0.1, 'bolls': 0.1, 'complained': 0.1, 'wiff': 0.1, 'schmucks': 0.1, 'cromedalbino': 0.1, 'long': 0.1, 'along': 0.1, 'game': 0.1, 'names': 0.1, 'until': 0.1, 'experience': 0.1, 'geneticallymutatedsoldiers': 0.1, 'killing': 0.1, 'schweiger': 0.1, 'players': 0.1, 'poop': 0.1, 'krieger': 0.1, 'tils': 0.1, 'shenanigans': 0.1, 'nice': 0.1, 'scheisse': 0.1, 'mr': 0.1, 'moeller': 0.1, 'german': 0.1, 'reason': 0.1, 'bought': 0.1, 'meaning': 0.1, 'warned': 0.1, 'gets': 0.1, 'countrymen': 0.1, 'schemed': 0.1, 'most': 0.3, 'mercs': 0.1, 'makes': 0.1, 'ago': 0.1, 'disappointed': 0.1, 'yes': 0.1, 'before': 0.1, 'legion': 0.1, 'areas': 0.1, 'shoot': 0.1, 'worth': 0.1, 'cry': 0.1, 'kier': 0.1, 'actually': 0.1, 'play': 0.2, 'trees': 0.1, 'cannot': 0.2, 'annoying': 0.1, 'work': 0.1, 'demented': 0.1, 'mad': 0.1, 'boll': 0.1, 'vancouver': 0.1, 'him': 0.1, 'person': 0.1, 'postal': 0.1, 'what': 0.4, 'wanna': 0.1, 'know': 0.2, 'hail': 0.1, 'looked': 0.1, 'dudes': 0.1, 'take': 0.1, 'udo': 0.1, 'appreciate': 0.1, 'text': 0.1, 'other': 0.3, 'scottish': 0.1, 'saying': 0.1, 'victorian': 0.1, 'bowdler': 0.1, 'hence': 0.1, 'do': 0.1, 'keep': 0.1, 'cut': 0.1, 'composition': 0.1, 'lines': 0.1, 'my': 0.3, 'forte': 0.1, 'era': 0.1, 'because': 0.1, 'perfection': 0.1, 'say': 0.2, 'words': 0.1, 'ruin': 0.1, 'trying': 0.1, 'favorite': 0.1, 'write': 0.1, 'why': 0.3, 'shakespeare': 0.1, 'bowdlerization': 0.1, 'tried': 0.1, 'certain': 0.1, 'bring': 0.1, 'does': 0.1, 'improve': 0.1, 'ten': 0.1, 'rev': 0.1, 'english': 0.1, 'masses': 0.1, 'spent': 0.1, 'everybody': 0.1, 'insights': 0.1, 'town': 0.1, 'stock': 0.1, 'sort': 0.1, 'thinking': 0.1, 'money': 0.2, 'amateurish': 0.1, 'intrigues': 0.1, 'get': 0.1, 'wasted': 0.1, 'million': 0.1, 'bizarre': 0.2, 'starving': 0.1, 'roles': 0.1, 'pass': 0.1, 'their': 0.1, 'arquette': 0.1, 'relationship': 0.1, 'encounters': 0.1, 'stereotyped': 0.1, 'bisexual': 0.1, 'lessons': 0.1, 'nonsensewhat': 0.1, 'realize': 0.1, 'kind': 0.1, 'erotic': 0.1, 'skin': 0.1, 'videotaped': 0.1, 'supposed': 0.1, 'absurd': 0.1, 'ever': 0.1, 'africa': 0.1, 'stilted': 0.1, 'lots': 0.1, 'unbelievable': 0.1, 'project': 0.1, 'heterosexual': 0.1, 'bits': 0.1, 'learned': 0.1, 'aids': 0.1, 'involved': 0.1, 'midwest': 0.1, 'could': 0.3, 'nowhere': 0.1, 'quite': 0.1, 'drawn': 0.1, 'school': 0.1, 'rosanna': 0.1, 'ridiculous': 0.1, 'dance': 0.1, 'miles': 0.1, 'high': 0.1, 'children': 0.2, 'waitit': 0.1, 'except': 0.1, 'character': 0.1, 'matrixor': 0.1, 'stings': 0.1, 'blatantly': 0.1, 'vader': 0.1, 'theme': 0.1, 'humans': 0.1, 'vs': 0.1, 'destroy': 0.1, 'juvenile': 0.1, 'upuh': 0.1, 'wraps': 0.1, 'too': 0.1, 'your': 0.1, 'hypnotizes': 0.1, 'development': 0.1, 'wasn': 0.1, 'into': 0.1, 'return': 0.1, 'line': 0.1, 'disappointment': 0.1, 'someone': 0.1, 'tell': 0.1, 'wars': 0.1, 'adult': 0.1, 'hello': 0.1, 'beginning': 0.1, 'save': 0.1, 'emotional': 0.1, 'ghost': 0.1, 'rushed': 0.1, 'both': 0.1, 'wood': 0.1, 'running': 0.1, 'conclusion': 0.1, 'top': 0.1, 'victim': 0.1, 'busy': 0.1, 'final': 0.1, 'machine': 0.1, 'elijah': 0.1, 'minute': 0.1, 'exactly': 0.1, 'sword': 0.1, 'had': 0.1, 'being': 0.1, 'fight': 0.1, 'horrible': 0.1, 'lotr': 0.1, 'obee': 0.1, 'terminator': 0.1, 'either': 0.1, 'continuous': 0.1, 'chance': 0.1, 'examples': 0.1, 'nazi': 0.1, 'frodo': 0.1, 'spider': 0.1, 'matrix': 0.1, 'kings': 0.1, 'wanted': 0.1, 'stolen': 0.1, 'yoda': 0.1, 'attacked': 0.1, 'attachment': 0.1, 'naked': 0.1, 'taken': 0.1, 'against': 0.1, 'accounts': 0.1, 'script': 0.1, 'artist': 0.1, 'renaissance': 0.1, 'liberties': 0.1, 'enough': 0.1, 'female': 0.1, 'hours': 0.1, 'saved': 0.1, 'capped': 0.1, 'fine': 0.1, 'globe': 0.1, 'version': 0.1, 'come': 0.1, 'factual': 0.1, 'summary': 0.1, 'painter': 0.1, 'dishwaterdull': 0.1, 'd': 0.1, 'mangled': 0.1, 'simply': 0.1, 'brevity': 0.1, 'couple': 0.1, 'facts': 0.1, 'perfectly': 0.1, 'rest': 0.1, 'golden': 0.1, 'complaint': 0.1, 'weren': 0.1, 'recognition': 0.1, 'nominated': 0.1, 'suppose': 0.1, 'favored': 0.1, 'hurriedly': 0.1, 'famous': 0.1, 'ourselves': 0.1, 'stinkers': 0.1}\n"
     ]
    }
   ],
   "source": [
    "dic_contagem_negativo = {}\n",
    "for i in range(len(df_negativo)):\n",
    "    lista_arrumada = limpa_texto_review(df_negativo.iloc[i]['review'])\n",
    "    lista_arrumada_unique = list(set(lista_arrumada))\n",
    "\n",
    "    for palavras in lista_arrumada_unique:    \n",
    "        if palavras not in dic_contagem_negativo:\n",
    "            dic_contagem_negativo[palavras] = 1\n",
    "        else:\n",
    "            dic_contagem_negativo[palavras] += 1\n",
    "\n",
    "dic_probabilidades_negativo = {}\n",
    "for palavras, contagem in dic_contagem_negativo.items():\n",
    "    dic_probabilidades_negativo[palavras] = contagem/len(df_negativo)\n",
    "\n",
    "dic_probabilidades_barrada_negativo = {}\n",
    "for palavra, probabilidade in dic_probabilidades_negativo.items():\n",
    "    dic_probabilidades_barrada_negativo[palavra] = 1-probabilidade\n",
    "\n",
    "for palavras in lista_positivo:\n",
    "    if palavras not in dic_probabilidades_barrada_negativo:\n",
    "        dic_probabilidades_barrada_negativo[palavras] = 1\n",
    "print(dic_probabilidades_negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'manyaryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'moreso', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romanceoz', 'doesn', 't', 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewingthats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side']\n",
      "-89.7431982722674 0.0\n",
      "1\n",
      "{0: 'positive'}\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "p_palavras, indice_acerto = 0, 0\n",
    "\n",
    "dic={}\n",
    "for i in range(len(df_teste)):\n",
    "    o = 0\n",
    "    p_negativa, p_positiva = 0, 0\n",
    "    negativo_confirmado,positivo_confirmado = False,False\n",
    "    lista_arrumada = limpa_texto_review(df_teste.iloc[i]['review'])\n",
    "    \n",
    "    for palavras in lista_arrumada:  \n",
    "        print(lista_arrumada)\n",
    "        break\n",
    "        if palavras in dic_probabilidades_positivo:\n",
    "            p_positiva += math.log10(dic_probabilidades_positivo[palavras]+0.001)\n",
    "     \n",
    "        else:\n",
    "            negativo_confirmado = True\n",
    "        \n",
    "        if palavras in dic_probabilidades_negativo:\n",
    "            p_negativa += math.log10(dic_probabilidades_negativo[palavras]+0.001)\n",
    "        else:\n",
    "            positivo_confirmado = True\n",
    "    for palavras2 in lista_total:    \n",
    "        if palavras2 not in lista_arrumada:\n",
    "            p_positiva += math.log10(dic_probabilidades_barrada_positivo[palavras2]+0.001)\n",
    "        if palavras2 not in lista_arrumada:\n",
    "            p_negativa += math.log10(dic_probabilidades_barrada_negativo[palavras2]+0.001)\n",
    "            o += math.log10(dic_probabilidades_barrada_positivo[palavras2]+0.001)\n",
    "    if positivo_confirmado:\n",
    "        dic[i] = 'positive'\n",
    "    elif negativo_confirmado:        \n",
    "        dic[i] = 'negative'\n",
    "    else:   \n",
    "        if p_positiva > p_negativa:\n",
    "            dic[i] = 'positive'\n",
    "        else:\n",
    "            dic[i] = 'negative'\n",
    "    print(o, p_positiva - o)\n",
    "    break\n",
    "for i in dic:\n",
    "    if dic[i] == df_teste.iloc[i]['sentiment']:\n",
    "        indice_acerto += 1\n",
    "\n",
    "print(indice_acerto)\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
